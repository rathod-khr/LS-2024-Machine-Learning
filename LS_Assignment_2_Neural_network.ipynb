{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPlIZu7V4B6DHTlzskbz/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uday-ML/LS-2024-Machine-Learning/blob/main/LS_Assignment_2_Neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip homer_bart.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzRKTCwOs9Bl",
        "outputId": "b7cf0079-6bfe-4d14-d91f-99b565eab838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  homer_bart.zip\n",
            "replace Bart/bart58.bmp? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmuYezo3oKZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4917bcf-381f-4f85-eb67-046ab6a2d4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 64, 64, 3)\n",
            "(32, 64, 64, 3)\n",
            "(32, 64, 64, 3)\n",
            "(32, 64, 64, 3)\n",
            "(32, 64, 64, 3)\n",
            "(32, 64, 64, 3)\n",
            "(32, 64, 64, 3)\n",
            "(32, 64, 64, 3)\n",
            "(13, 64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "#base_dir = '/content/drive/My Drive/path_to_extracted_files'  # Update this to your extraction path\n",
        "bart_dir = 'Bart'\n",
        "homer_dir = os.path.join('Homer')\n",
        "\n",
        "# Get the list of BMP image file paths from both folders\n",
        "file_paths = []\n",
        "for dir_path in [bart_dir, homer_dir]:\n",
        "    file_paths += [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.bmp')]\n",
        "\n",
        "# Function to load and preprocess BMP images\n",
        "def load_and_preprocess_image(file_path):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_bmp(image, channels=3)  # Decode BMP images\n",
        "    image = tf.image.resize(image, [64, 64])\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "    return image\n",
        "\n",
        "# Create a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
        "dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Batch the dataset\n",
        "batch_size = 32\n",
        "dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# To iterate through the dataset\n",
        "for batch in dataset:\n",
        "    # Perform your operations on the batch\n",
        "    print(batch.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "bart_dir = os.path.join('Bart')\n",
        "homer_dir = os.path.join('Homer')\n",
        "\n",
        "# Get the list of BMP image file paths from both folders\n",
        "file_paths_bart = [os.path.join(bart_dir, f) for f in os.listdir(bart_dir) if f.endswith('.bmp')]\n",
        "file_paths_homer = [os.path.join(homer_dir, f) for f in os.listdir(homer_dir) if f.endswith('.bmp')]\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_and_preprocess_image(file_path):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_bmp(image, channels=3)  # Decode BMP images\n",
        "    image = tf.image.resize(image, [64, 64])\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "    return image\n",
        "\n",
        "# Load images and labels\n",
        "images = []\n",
        "labels = []\n",
        "for file_path in file_paths_bart:\n",
        "    images.append(load_and_preprocess_image(file_path))\n",
        "    labels.append(0)  # Assuming 0 represents \"Bart\"\n",
        "for file_path in file_paths_homer:\n",
        "    images.append(load_and_preprocess_image(file_path))\n",
        "    labels.append(1)  # Assuming 1 represents \"Homer\"\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split data into training and test sets (9:1 ratio)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout for regularization\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=20, batch_size=32, validation_split=0.0)  # No validation set, only training\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V17P2kgzpKe",
        "outputId": "84146fe1-ac05-4a7b-9e2e-83f4869d52aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 5s 327ms/step - loss: 0.6855 - accuracy: 0.5661\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 2s 192ms/step - loss: 0.6694 - accuracy: 0.6074\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 0.6598 - accuracy: 0.6074\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 0.6565 - accuracy: 0.6074\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 2s 192ms/step - loss: 0.6479 - accuracy: 0.6157\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 0.6378 - accuracy: 0.6116\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 0.6109 - accuracy: 0.6488\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 2s 191ms/step - loss: 0.5997 - accuracy: 0.6529\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 3s 320ms/step - loss: 0.5834 - accuracy: 0.6860\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 3s 317ms/step - loss: 0.5492 - accuracy: 0.7355\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 2s 194ms/step - loss: 0.5152 - accuracy: 0.7397\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 0.5012 - accuracy: 0.7934\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 0.4899 - accuracy: 0.7934\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 0.4616 - accuracy: 0.7727\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 0.4396 - accuracy: 0.8306\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 0.4241 - accuracy: 0.7975\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 0.4188 - accuracy: 0.8264\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 2s 314ms/step - loss: 0.3923 - accuracy: 0.8058\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 3s 318ms/step - loss: 0.3946 - accuracy: 0.8140\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 2s 209ms/step - loss: 0.3853 - accuracy: 0.8140\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.5649 - accuracy: 0.7778\n",
            "Test accuracy: 0.7777777910232544\n"
          ]
        }
      ]
    }
  ]
}